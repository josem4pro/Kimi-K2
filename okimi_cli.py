#!/home/jose/Kimi-K2/venv/bin/python3
"""
Kimi K2 Thinking - OpenRouter Wrapper CLI
Acceso simplificado al modelo Kimi K2 vÃ­a OpenRouter con todas las capacidades activadas.

Uso:
  okimi                           # Modo interactivo
  okimi "tu pregunta aquÃ­"        # Modo comando Ãºnico
  okimi -h, --help                # Ayuda
  okimi --heavy "pregunta"        # Heavy Mode (8 trayectorias paralelas)
  okimi --simple "pregunta"       # Modo simple (sin razonamiento extendido)
"""

import os
import sys
import json
from pathlib import Path

# Intentar importar dependencias
try:
    from dotenv import load_dotenv
    from openai import OpenAI
    import requests
except ImportError as e:
    print(f"âŒ Error: Falta dependencia: {e}")
    print("\nðŸ”§ SoluciÃ³n: Instala las dependencias con:")
    print("   pip install python-dotenv openai requests")
    sys.exit(1)

# Colores para terminal
class Colors:
    HEADER = '\033[95m'
    OKBLUE = '\033[94m'
    OKCYAN = '\033[96m'
    OKGREEN = '\033[92m'
    WARNING = '\033[93m'
    FAIL = '\033[91m'
    ENDC = '\033[0m'
    BOLD = '\033[1m'
    UNDERLINE = '\033[4m'

def print_banner():
    """Muestra el banner de inicio"""
    banner = f"""
{Colors.OKCYAN}â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘              KIMI K2 THINKING (OpenRouter)                â•‘
â•‘              Moonshot AI - Open Agentic Intelligence      â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•{Colors.ENDC}
"""
    print(banner)

def load_api_key():
    """Carga la API key desde ~/.env"""
    env_path = Path.home() / '.env'

    if not env_path.exists():
        print(f"{Colors.FAIL}âŒ Error: No se encuentra ~/.env{Colors.ENDC}")
        print(f"\n{Colors.WARNING}ðŸ”§ SoluciÃ³n:{Colors.ENDC}")
        print("   1. Crea el archivo: touch ~/.env")
        print("   2. Agrega tu key: echo 'OPENROUTER_API_KEY=tu_key_aqui' >> ~/.env")
        sys.exit(1)

    load_dotenv(env_path)
    api_key = os.getenv('OPENROUTER_API_KEY')

    if not api_key:
        print(f"{Colors.FAIL}âŒ Error: OPENROUTER_API_KEY no encontrada en ~/.env{Colors.ENDC}")
        print(f"\n{Colors.WARNING}ðŸ”§ SoluciÃ³n:{Colors.ENDC}")
        print("   Agrega tu key: echo 'OPENROUTER_API_KEY=tu_key_aqui' >> ~/.env")
        sys.exit(1)

    print(f"{Colors.OKGREEN}âœ“ API Key cargada: {api_key[:20]}...{Colors.ENDC}")
    return api_key

def create_client(api_key):
    """Crea el cliente de OpenAI configurado para OpenRouter"""
    client = OpenAI(
        api_key=api_key,
        base_url="https://openrouter.ai/api/v1",
        default_headers={
            "HTTP-Referer": "https://github.com/josem4pro/Kimi-K2",  # Para rankings en openrouter.ai
            "X-Title": "Kimi K2 CLI by josem4pro",  # Para rankings en openrouter.ai
        }
    )
    print(f"{Colors.OKGREEN}âœ“ Cliente configurado: openrouter.ai{Colors.ENDC}")
    return client

def get_credits_balance(api_key):
    """Obtiene el balance de crÃ©ditos de OpenRouter"""
    try:
        # Intentar primero el endpoint de crÃ©ditos (para cuentas prepago)
        credits_response = requests.get(
            "https://openrouter.ai/api/v1/credits",
            headers={"Authorization": f"Bearer {api_key}"},
            timeout=5
        )

        if credits_response.status_code == 200:
            credits_data = credits_response.json()
            if 'data' in credits_data:
                total_credits = credits_data['data'].get('total_credits', 0)
                total_usage = credits_data['data'].get('total_usage', 0)
                balance = total_credits - total_usage

                return {
                    'success': True,
                    'is_prepaid': True,
                    'total_credits': total_credits,
                    'usage': total_usage,
                    'balance': balance
                }

        # Si falla, intentar el endpoint de auth/key (cuentas con lÃ­mite)
        auth_response = requests.get(
            "https://openrouter.ai/api/v1/auth/key",
            headers={"Authorization": f"Bearer {api_key}"},
            timeout=5
        )

        if auth_response.status_code == 200:
            data = auth_response.json()
            if 'data' in data:
                limit = data['data'].get('limit')
                usage = data['data'].get('usage', 0)

                if limit is not None and limit > 0:
                    remaining = limit - usage
                    return {
                        'success': True,
                        'is_prepaid': False,
                        'limit': limit,
                        'usage': usage,
                        'remaining': remaining
                    }

        return {'success': False, 'error': 'No se pudo obtener el balance'}

    except Exception as e:
        return {'success': False, 'error': str(e)}

def get_tools():
    """Define las herramientas disponibles para el modelo (solo bÃºsqueda web por ahora)"""
    return [
        {
            "type": "function",
            "function": {
                "name": "buscar_informacion",
                "description": "Busca informaciÃ³n en internet usando SearXNG (meta-buscador con mÃºltiples motores: ArXiv, Google Scholar, GitHub, StackOverflow, Brave, DuckDuckGo)",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "consulta": {
                            "type": "string",
                            "description": "QuÃ© buscar (ej: 'chutes.ai API documentation balance endpoint')"
                        }
                    },
                    "required": ["consulta"]
                }
            }
        }
    ]

def execute_tool(tool_name, arguments):
    """Ejecuta una herramienta y retorna el resultado"""
    try:
        args = json.loads(arguments) if isinstance(arguments, str) else arguments

        if tool_name == "buscar_informacion":
            query = args.get("consulta", "")

            # Usar SearXNG local (puerto 8888)
            response = requests.get(
                "http://localhost:8888/search",
                params={"q": query, "format": "json"},
                timeout=10
            )

            if response.status_code == 200:
                data = response.json()
                results = data.get("results", [])[:5]  # Top 5 resultados

                if not results:
                    return "No se encontraron resultados para esta bÃºsqueda."

                # Formatear resultados
                formatted = f"Resultados de bÃºsqueda para '{query}':\n\n"
                for i, result in enumerate(results, 1):
                    title = result.get("title", "Sin tÃ­tulo")
                    url = result.get("url", "")
                    content = result.get("content", "")
                    engine = result.get("engine", "")

                    formatted += f"{i}. {title}\n"
                    formatted += f"   URL: {url}\n"
                    if content:
                        # Limitar contenido a 200 caracteres
                        content_preview = content[:200] + "..." if len(content) > 200 else content
                        formatted += f"   Contenido: {content_preview}\n"
                    formatted += f"   Motor: {engine}\n\n"

                return formatted
            else:
                return f"Error al buscar: HTTP {response.status_code}"

        else:
            return f"Tool '{tool_name}' no implementada aÃºn"

    except Exception as e:
        return f"Error al ejecutar {tool_name}: {str(e)}"

def query_kimi(client, prompt, heavy_mode=False, simple_mode=False, web_mode=False, interactive=False, api_key=None):
    """
    Consulta a Kimi K2 Thinking vÃ­a OpenRouter con todas las capacidades activadas

    Args:
        client: Cliente de OpenAI configurado
        prompt: Pregunta/prompt para el modelo
        heavy_mode: Activar Heavy Mode (8 trayectorias paralelas + tools)
        simple_mode: Modo simple sin razonamiento extendido
        web_mode: Activar herramientas (web, cÃ³digo, memoria) sin heavy mode
        interactive: Modo interactivo (permite conversaciÃ³n continua)
        api_key: API key para consultar balance de crÃ©ditos
    """

    # ConfiguraciÃ³n base
    config = {
        "model": "moonshotai/kimi-k2-thinking",
        "messages": [
            {
                "role": "system",
                "content": "Eres Kimi K2 Thinking, un modelo avanzado de razonamiento profundo. "
                          "Razona paso a paso y sÃ© exhaustivo en tus respuestas. "
                          "Tienes acceso a herramientas para bÃºsqueda web, ejecuciÃ³n de cÃ³digo y memoria distribuida."
            },
            {"role": "user", "content": prompt}
        ],
        "max_tokens": 16384,  # Respuestas exhaustivas (~12,000 palabras)
        "temperature": 0.3,  # Balance entre precisiÃ³n y creatividad
    }

    # Activar herramientas si se solicita (web_mode o heavy_mode)
    if web_mode or heavy_mode:
        config["tools"] = get_tools()
        config["tool_choice"] = "auto"

    # Activar Heavy Mode si se solicita (8 trayectorias + tools)
    if heavy_mode:
        config["extra_body"] = {"heavy_mode": True}
        print(f"\n{Colors.WARNING}âš¡ Heavy Mode activado: 8 trayectorias paralelas + herramientas{Colors.ENDC}")
    elif web_mode:
        print(f"\n{Colors.OKCYAN}ðŸŒ Web Mode activado: razonamiento + herramientas{Colors.ENDC}")

    if simple_mode:
        config["max_tokens"] = 1000
        config["temperature"] = 0.1
        print(f"\n{Colors.OKBLUE}ðŸš€ Modo simple: respuesta rÃ¡pida{Colors.ENDC}")

    print(f"\n{Colors.OKGREEN}âœ“ Modelo listo: Kimi K2 Thinking (OpenRouter){Colors.ENDC}")
    print(f"{Colors.OKBLUE}ðŸ“Š Capacidades activas:{Colors.ENDC}")
    print(f"   â€¢ Contexto: 256K tokens")

    # Indicar si las herramientas estÃ¡n activas
    if web_mode or heavy_mode:
        print(f"   â€¢ Tool-calling: âœ“ Habilitado (bÃºsqueda web vÃ­a SearXNG)")
    else:
        print(f"   â€¢ Tool-calling: âœ— Deshabilitado (respuesta directa)")

    print(f"   â€¢ Max tokens: {config['max_tokens']}")
    print(f"   â€¢ Temperature: {config['temperature']}")
    print(f"   â€¢ Provider: OpenRouter")

    try:
        print(f"\n{Colors.OKCYAN}ðŸ¤” Procesando...{Colors.ENDC}\n")

        # Primera llamada al modelo
        response = client.chat.completions.create(**config)
        message = response.choices[0].message

        # Si el modelo quiere usar tools, ejecutarlas
        if hasattr(message, 'tool_calls') and message.tool_calls:
            print(f"{Colors.WARNING}ðŸ”§ Ejecutando herramientas...{Colors.ENDC}\n")

            # Agregar el mensaje del asistente con tool_calls
            # Convertir tool_calls a dict serializables
            tool_calls_list = []
            for tc in message.tool_calls:
                tool_calls_list.append({
                    "id": tc.id,
                    "type": "function",
                    "function": {
                        "name": tc.function.name,
                        "arguments": tc.function.arguments
                    }
                })

            config["messages"].append({
                "role": "assistant",
                "content": None,  # Debe ser None cuando hay tool_calls
                "tool_calls": tool_calls_list
            })

            # Ejecutar cada tool y agregar resultados
            for tool_call in message.tool_calls:
                tool_name = tool_call.function.name
                tool_args = tool_call.function.arguments

                print(f"  ðŸ“¡ {tool_name}({tool_args[:80]}...)" if len(tool_args) > 80 else f"  ðŸ“¡ {tool_name}({tool_args})")

                # Ejecutar la tool
                tool_result = execute_tool(tool_name, tool_args)

                # Agregar el resultado a messages
                config["messages"].append({
                    "role": "tool",
                    "tool_call_id": tool_call.id,
                    "name": tool_name,
                    "content": tool_result
                })

                print(f"  âœ“ Resultado obtenido ({len(tool_result)} caracteres)\n")

            # Remover tools de config para la segunda llamada
            config_second = config.copy()
            config_second.pop("tools", None)
            config_second.pop("tool_choice", None)

            # Segunda llamada al modelo con los resultados de las tools
            print(f"{Colors.OKCYAN}ðŸ¤” Generando respuesta final...{Colors.ENDC}\n")
            response = client.chat.completions.create(**config_second)
            message = response.choices[0].message

        # Mostrar respuesta final
        print(f"{Colors.BOLD}â•â•â• RESPUESTA â•â•â•{Colors.ENDC}\n")
        if message.content:
            print(message.content)
        else:
            print(f"{Colors.WARNING}(Sin contenido de texto){Colors.ENDC}")

        # Mostrar uso de tokens
        if response.usage:
            print(f"\n{Colors.OKBLUE}â•â•â• USO DE TOKENS â•â•â•{Colors.ENDC}")
            print(f"  Input: {response.usage.prompt_tokens:,} tokens")
            print(f"  Output: {response.usage.completion_tokens:,} tokens")
            print(f"  Total: {response.usage.total_tokens:,} tokens")

            # Calcular costo aproximado (OpenRouter pricing para Kimi K2)
            # Precios: $0.60/1M input, $2.50/1M output (via OpenRouter)
            cost_input = (response.usage.prompt_tokens / 1_000_000) * 0.60
            cost_output = (response.usage.completion_tokens / 1_000_000) * 2.50
            total_cost = cost_input + cost_output
            print(f"\n  {Colors.BOLD}ðŸ’° Costo de esta consulta: ${total_cost:.6f} USD{Colors.ENDC}")

            # Obtener y mostrar balance de crÃ©ditos de OpenRouter
            if api_key:
                balance_info = get_credits_balance(api_key)
                if balance_info['success']:
                    # Cuenta prepago (crÃ©ditos prepagados)
                    if balance_info.get('is_prepaid'):
                        balance = balance_info['balance']
                        total_credits = balance_info['total_credits']
                        usage = balance_info['usage']

                        # Color segÃºn el balance disponible
                        if balance > 10:
                            color = Colors.OKGREEN
                            status = "âœ“"
                        elif balance > 5:
                            color = Colors.WARNING
                            status = "âš "
                        else:
                            color = Colors.FAIL
                            status = "âš "

                        print(f"  {color}{status} Balance disponible: ${balance:.2f} USD{Colors.ENDC}")
                        print(f"  {Colors.OKBLUE}   (Total: ${total_credits:.2f} | Gastado: ${usage:.4f}){Colors.ENDC}")
                    # Cuenta con lÃ­mite fijo
                    else:
                        remaining = balance_info['remaining']
                        limit = balance_info['limit']
                        usage = balance_info['usage']

                        # Color segÃºn el balance disponible
                        if remaining > 10:
                            color = Colors.OKGREEN
                            status = "âœ“"
                        elif remaining > 5:
                            color = Colors.WARNING
                            status = "âš "
                        else:
                            color = Colors.FAIL
                            status = "âš "

                        print(f"  {color}{status} Saldo disponible: ${remaining:.2f} USD{Colors.ENDC}")
                        print(f"  {Colors.OKBLUE}   (LÃ­mite: ${limit:.2f} | Usado: ${usage:.2f}){Colors.ENDC}")
                else:
                    print(f"  {Colors.WARNING}âš  No se pudo obtener el saldo: {balance_info.get('error', 'Error desconocido')}{Colors.ENDC}")

        print()  # LÃ­nea en blanco al final

        return message.content

    except Exception as e:
        print(f"\n{Colors.FAIL}âŒ Error al consultar Kimi K2: {e}{Colors.ENDC}")
        print(f"\n{Colors.WARNING}ðŸ”§ Posibles causas:{Colors.ENDC}")
        print("   â€¢ LÃ­mite de requests alcanzado")
        print("   â€¢ API key invÃ¡lida o expirada")
        print("   â€¢ Problemas de conectividad")
        print("   â€¢ CrÃ©ditos insuficientes en OpenRouter")
        print("\n   Verifica tu cuenta en: https://openrouter.ai")
        sys.exit(1)

def interactive_mode(client, api_key):
    """Modo interactivo - conversaciÃ³n continua"""
    print(f"\n{Colors.OKGREEN}ðŸ’¬ Modo interactivo activado{Colors.ENDC}")
    print(f"{Colors.WARNING}Escribe 'salir', 'exit' o 'quit' para terminar{Colors.ENDC}")
    print(f"{Colors.WARNING}Escribe 'heavy: tu pregunta' para Heavy Mode{Colors.ENDC}")
    print(f"{Colors.WARNING}Escribe 'web: tu pregunta' para Web Mode{Colors.ENDC}\n")

    while True:
        try:
            prompt = input(f"{Colors.BOLD}TÃº âžœ {Colors.ENDC}").strip()

            if not prompt:
                continue

            if prompt.lower() in ['salir', 'exit', 'quit']:
                print(f"\n{Colors.OKCYAN}ðŸ‘‹ Â¡Hasta pronto!{Colors.ENDC}")
                break

            # Detectar modo especial
            heavy = False
            web = False

            if prompt.lower().startswith('heavy:'):
                heavy = True
                prompt = prompt[6:].strip()
            elif prompt.lower().startswith('web:'):
                web = True
                prompt = prompt[4:].strip()

            query_kimi(client, prompt, heavy_mode=heavy, web_mode=web, interactive=True, api_key=api_key)
            print()  # Separador entre respuestas

        except KeyboardInterrupt:
            print(f"\n\n{Colors.OKCYAN}ðŸ‘‹ Â¡Hasta pronto!{Colors.ENDC}")
            break
        except Exception as e:
            print(f"\n{Colors.FAIL}âŒ Error: {e}{Colors.ENDC}\n")

def show_help():
    """Muestra la ayuda del comando"""
    help_text = f"""
{Colors.BOLD}KIMI K2 THINKING (OpenRouter) - Wrapper CLI{Colors.ENDC}

{Colors.OKGREEN}Uso bÃ¡sico:{Colors.ENDC}
  okimi                           Modo interactivo (conversaciÃ³n continua)
  okimi "tu pregunta aquÃ­"        Modo comando Ãºnico

{Colors.OKGREEN}Opciones:{Colors.ENDC}
  -h, --help                     Muestra esta ayuda
  --simple "pregunta"            Modo simple (respuesta rÃ¡pida sin razonamiento)
  --web "pregunta"               Web Mode (razonamiento + herramientas)
  --heavy "pregunta"             Heavy Mode (8 trayectorias + herramientas)

{Colors.OKGREEN}Ejemplos:{Colors.ENDC}
  okimi "Â¿QuÃ© es un sistema de memoria distribuida?"
  okimi --simple "Resume en 3 lÃ­neas quÃ© es K2 Thinking"
  okimi --web "Busca info reciente sobre Kimi K2"
  okimi --heavy "DiseÃ±a arquitectura completa multi-agente"

{Colors.OKGREEN}Capacidades activadas:{Colors.ENDC}
  âœ“ Contexto: 256K tokens
  âœ“ Razonamiento extendido: 200-300 pasos
  âœ“ Transparencia: cadenas de pensamiento visibles
  âœ“ Provider: OpenRouter (acceso a 100+ modelos)

{Colors.OKGREEN}Modos disponibles:{Colors.ENDC}
  â€¢ Simple (--simple): Respuesta rÃ¡pida sin razonamiento extendido
  â€¢ Normal (default): Razonamiento completo sin herramientas
  â€¢ Web (--web): Razonamiento + herramientas (1 trayectoria)
  â€¢ Heavy (--heavy): Razonamiento + herramientas (8 trayectorias)

{Colors.OKGREEN}ConfiguraciÃ³n:{Colors.ENDC}
  API Key: ~/.env (OPENROUTER_API_KEY)
  Endpoint: openrouter.ai/api/v1
  Modelo: moonshotai/kimi-k2-thinking

{Colors.OKGREEN}Diferencia con kimi (Chutes.ai):{Colors.ENDC}
  â€¢ okimi usa OpenRouter (acceso multi-proveedor)
  â€¢ kimi usa Chutes.ai (infraestructura descentralizada)
  â€¢ Mismo modelo, diferentes proveedores
  â€¢ Precios similares, SLAs diferentes

{Colors.OKGREEN}MÃ¡s informaciÃ³n:{Colors.ENDC}
  GitHub: https://github.com/moonshotai/Kimi-K2
  Paper: arXiv:2501.17055
  OpenRouter: https://openrouter.ai
  Dashboard: https://openrouter.ai/dashboard
"""
    print(help_text)

def main():
    """FunciÃ³n principal"""

    # Verificar argumentos
    if len(sys.argv) > 1:
        arg = sys.argv[1]

        # Ayuda
        if arg in ['-h', '--help', 'help']:
            print_banner()
            show_help()
            sys.exit(0)

        # Simple Mode
        if arg == '--simple' and len(sys.argv) > 2:
            print_banner()
            api_key = load_api_key()
            client = create_client(api_key)
            prompt = ' '.join(sys.argv[2:])
            query_kimi(client, prompt, simple_mode=True, api_key=api_key)
            sys.exit(0)

        # Web Mode (herramientas sin heavy)
        if arg == '--web' and len(sys.argv) > 2:
            print_banner()
            api_key = load_api_key()
            client = create_client(api_key)
            prompt = ' '.join(sys.argv[2:])
            query_kimi(client, prompt, web_mode=True, api_key=api_key)
            sys.exit(0)

        # Heavy Mode (8 trayectorias + herramientas)
        if arg == '--heavy' and len(sys.argv) > 2:
            print_banner()
            api_key = load_api_key()
            client = create_client(api_key)
            prompt = ' '.join(sys.argv[2:])
            query_kimi(client, prompt, heavy_mode=True, api_key=api_key)
            sys.exit(0)

        # Comando Ãºnico (cualquier texto)
        print_banner()
        api_key = load_api_key()
        client = create_client(api_key)
        prompt = ' '.join(sys.argv[1:])
        query_kimi(client, prompt, api_key=api_key)
        sys.exit(0)

    # Modo interactivo (sin argumentos)
    print_banner()
    api_key = load_api_key()
    client = create_client(api_key)
    interactive_mode(client, api_key)

if __name__ == '__main__':
    main()
